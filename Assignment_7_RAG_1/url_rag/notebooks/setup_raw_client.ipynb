{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960d582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Study\\\\Programs\\\\TSAI\\\\EAG_V1\\\\Assignment_7_RAG_1\\\\2_URL_RAG\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db019d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Programs\\TSAI\\EAG_V1\\Assignment_7_RAG_1\\2_URL_RAG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579310f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f45a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8d8698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urllib3 SSL patched successfully\n",
      "httpx Client patched to disable SSL verification\n",
      "httpx AsyncHTTPTransport patched to disable SSL verification\n",
      "✅ SSL verification completely disabled at all levels\n",
      "SSL_CERT_FILE: None\n",
      "PYTHONHTTPSVERIFY: 0\n",
      "OPENAI_VERIFY_SSL_CERTS: false\n",
      "OPENAI_API_SKIP_VERIFY_SSL: true\n",
      "✅ SSL test success: 401\n"
     ]
    }
   ],
   "source": [
    "from client.llm_provider import default_llm #it is gpt-4o-mini\n",
    "from client.embedding_provider import OpenAIEmbeddingProvider #text-embedding-3-small\n",
    "from server.utils import read_yaml_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf779e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BpyL2jPDNNVIn6H6H7ghnQwSwFArF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f0bf3504-5ddb-4076-b4a3-a18d9332d830-0' usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "llm = default_llm.chat_model #it is gpt-4o-mini\n",
    "embedder = OpenAIEmbeddingProvider().embeddings #text-embedding-3-small\n",
    "\n",
    "\n",
    "print(llm.invoke(\"what is the capital of France?\"))\n",
    "print(len(embedder.embed_query(\"what is the capital of France?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b5ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'db_index_name': 'weburl_index', 'history_index_name': 'history_index', 'reset_index': False}\n"
     ]
    }
   ],
   "source": [
    "# read config\n",
    "config = read_yaml_file(\"client/config.yaml\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcaa716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Programs\\TSAI\\EAG_V1\\Assignment_7_RAG_1\\2_URL_RAG\\history_index\n"
     ]
    }
   ],
   "source": [
    "history_index_name = config[\"history_index_name\"]\n",
    "history_index_name = os.path.join(os.getcwd(), history_index_name)\n",
    "print(history_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c4d4b",
   "metadata": {},
   "source": [
    "#### Next steps \n",
    "- Perception code which will be used prepare the question based on the user query and chat history\n",
    "- Decision making code which will be used to decide the action based on the question and chat history\n",
    "- Action code which will be used to execute the action\n",
    "- Memory code which will be used to store the chat history\n",
    "- Client code which will be used to coordinate the conversation between the perception, decision making, action and memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8740b",
   "metadata": {},
   "source": [
    "### Perception Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6c07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "import json\n",
    "\n",
    "from memory import ConversationMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c0022c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebContentSearch(BaseModel):\n",
    "    enhanced_user_query: str = Field(\n",
    "        description=\"The enhanced user query to be searched on the web for similar content stored in the memory\"\n",
    "    )\n",
    "    no_of_results: int = Field(\n",
    "        1,\n",
    "        description=\"The number of results to be returned from the web search corresponding to the user query\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6912b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an intelligent assistant designed to refine user queries using current input and prior context. Your goal is to construct a precise, context-aware enhanced query that reflects the user’s true intent.\n",
    "\n",
    "Your responsibilities are:\n",
    "1. Analyze the current user message to understand the core request.\n",
    "2. Examine the chat history (a list of messages with sender and content) to identify:\n",
    "   - Any contextually relevant information.\n",
    "   - Follow-ups or references to previous discussions.\n",
    "3. Determine whether the current query is:\n",
    "   a. A continuation of a previous topic.\n",
    "   b. A new, unrelated query.\n",
    "\n",
    "Based on this analysis, follow the appropriate path:\n",
    "\n",
    "**If the current message relates to previous topics:**\n",
    "- Incorporate relevant prior context into the enhanced query.\n",
    "- Clarify ambiguous references or pronouns using information from the chat history.\n",
    "- Resolve under-specified requests by grounding them in previous conversations.\n",
    "\n",
    "**If the message is a new topic:**\n",
    "- Focus solely on the current message.\n",
    "- Do not infer or inject unrelated context from chat history.\n",
    "\n",
    "**Process for forming the enhanced user query:**\n",
    "1. Carefully review the current message.\n",
    "2. Analyze the chat history (most recent last) to extract relevant past content.\n",
    "3. Identify if the user is building on a previous conversation.\n",
    "4. Integrate any necessary clarifications, references, or details from the chat history.\n",
    "5. Output a concise, context-enriched, unambiguous enhanced query.\n",
    "\n",
    "**Inputs:**\n",
    "- `chat_history`: A list of dictionaries, each with keys `sender` and `content`.\n",
    "    {chat_history}\n",
    "- `user_query`: The latest message from the user.\n",
    "    {user_query}\n",
    "\n",
    "**Output Format:**\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33988807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perception_chain(llm) -> RunnableSequence:\n",
    "    \"\"\"\n",
    "    Creates and returns the perception chain for extracting travel search parameters.\n",
    "\n",
    "    Args:\n",
    "        default_llm: The default LLM to use for the chain.\n",
    "\n",
    "    Returns:\n",
    "        A LangChain runnable sequence that takes a user query and chat history,\n",
    "        and returns a TravelSearch object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up a parser\n",
    "    parser = PydanticOutputParser(pydantic_object=WebContentSearch)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"The user query is: {user_query}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    # Create and return the chain\n",
    "    return prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbadae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-05 20:56:56.978\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mcheck_and_reset_index\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mreset_index is set to True. Deleting existing index at 'd:\\Study\\Programs\\TSAI\\EAG_V1\\Assignment_7_RAG_1\\2_URL_RAG\\history_index'\u001b[0m\n",
      "\u001b[32m2025-07-05 20:56:56.980\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mcheck_and_reset_index\u001b[0m:\u001b[36m32\u001b[0m - \u001b[32m\u001b[1mSuccessfully deleted index folder 'd:\\Study\\Programs\\TSAI\\EAG_V1\\Assignment_7_RAG_1\\2_URL_RAG\\history_index'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "conv_id = uuid.uuid4()\n",
    "store = ConversationMemory(\n",
    "    embedder, index_folder=history_index_name, reset_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67e3ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "chat_history = store.get_conversation_as_lc_messages(str(conv_id))\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "895168ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What are all MLOPS tools which should be learnt to get a job in MLOPS?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4aec1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'user_query'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B50D56C220>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"enhanced_user_query\": {\"description\": \"The enhanced user query to be searched on the web for similar content stored in the memory\", \"title\": \"Enhanced User Query\", \"type\": \"string\"}, \"no_of_results\": {\"default\": 1, \"description\": \"The number of results to be returned from the web search corresponding to the user query\", \"title\": \"No Of Results\", \"type\": \"integer\"}}, \"required\": [\"enhanced_user_query\"]}\\n```'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['chat_history', 'format_instructions', 'user_query'], input_types={}, partial_variables={}, template='\\nYou are an intelligent assistant designed to refine user queries using current input and prior context. Your goal is to construct a precise, context-aware enhanced query that reflects the user’s true intent.\\n\\nYour responsibilities are:\\n1. Analyze the current user message to understand the core request.\\n2. Examine the chat history (a list of messages with sender and content) to identify:\\n   - Any contextually relevant information.\\n   - Follow-ups or references to previous discussions.\\n3. Determine whether the current query is:\\n   a. A continuation of a previous topic.\\n   b. A new, unrelated query.\\n\\nBased on this analysis, follow the appropriate path:\\n\\n**If the current message relates to previous topics:**\\n- Incorporate relevant prior context into the enhanced query.\\n- Clarify ambiguous references or pronouns using information from the chat history.\\n- Resolve under-specified requests by grounding them in previous conversations.\\n\\n**If the message is a new topic:**\\n- Focus solely on the current message.\\n- Do not infer or inject unrelated context from chat history.\\n\\n**Process for forming the enhanced user query:**\\n1. Carefully review the current message.\\n2. Analyze the chat history (most recent last) to extract relevant past content.\\n3. Identify if the user is building on a previous conversation.\\n4. Integrate any necessary clarifications, references, or details from the chat history.\\n5. Output a concise, context-enriched, unambiguous enhanced query.\\n\\n**Inputs:**\\n- `chat_history`: A list of dictionaries, each with keys `sender` and `content`.\\n    {chat_history}\\n- `user_query`: The latest message from the user.\\n    {user_query}\\n\\n**Output Format:**\\n{format_instructions}\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_query'], input_types={}, partial_variables={}, template='The user query is: {user_query}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001B50ED2E510>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001B50ED2EF90>, root_client=<openai.OpenAI object at 0x000001B50EBAFCB0>, root_async_client=<openai.AsyncOpenAI object at 0x000001B50ED2ECF0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), http_client=<client.llm_provider.InsecureClient object at 0x000001B50EBAC6E0>)\n",
       "| PydanticOutputParser(pydantic_object=<class '__main__.WebContentSearch'>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perception_chain = get_perception_chain(llm)\n",
    "perception_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feebc8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhanced_user_query='What are the essential MLOps tools and technologies that one should learn to secure a job in the MLOps field?' no_of_results=5\n"
     ]
    }
   ],
   "source": [
    "result = perception_chain.invoke(\n",
    "    {\"user_query\": user_query, \"chat_history\": chat_history}\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "039d43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the history object\n",
    "messages = [\n",
    "    {\"sender\": \"human\", \"content\": user_query},\n",
    "    {\"sender\": \"ai\", \"content\": result.enhanced_user_query},\n",
    "]\n",
    "store.store_conversation(str(conv_id), messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba9350c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'human', 'content': 'What are all MLOPS tools which should be learnt to get a job in MLOPS?'}, {'role': 'ai', 'content': 'What are the essential MLOps tools and technologies that one should learn to secure a job in the MLOps field?'}]\n",
      "enhanced_user_query='Can you provide two articles on essential MLOps tools and technologies that one should learn to secure a job in the MLOps field?' no_of_results=2\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Give me two articles on for the same topic?\"\n",
    "chat_history = store.get_conversation_as_lc_messages(str(conv_id))\n",
    "print(chat_history)\n",
    "\n",
    "result = perception_chain.invoke(\n",
    "    {\"user_query\": user_query, \"chat_history\": chat_history}\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3549120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the history object\n",
    "messages = [\n",
    "    {\"sender\": \"human\", \"content\": user_query},\n",
    "    {\"sender\": \"ai\", \"content\": result.enhanced_user_query},\n",
    "]\n",
    "store.store_conversation(str(conv_id), messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb06511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'human', 'content': 'What are all MLOPS tools which should be learnt to get a job in MLOPS?'}, {'role': 'ai', 'content': 'What are the essential MLOps tools and technologies that one should learn to secure a job in the MLOps field?'}, {'role': 'human', 'content': 'Give me two articles on for the same topic?'}, {'role': 'ai', 'content': 'Can you provide two articles on essential MLOps tools and technologies that one should learn to secure a job in the MLOps field?'}]\n"
     ]
    }
   ],
   "source": [
    "chat_history = store.get_conversation_as_lc_messages(str(conv_id))\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bff9de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function where we will pass the history object and a list of conversation and the chain\n",
    "# and it will keep processing the conversation and return the enhanced user query\n",
    "\n",
    "\n",
    "def process_conversation_and_enhance_query(\n",
    "    history_store, conversation_list, chain, conv_id\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a list of user queries (conversation_list) using the provided chain and history store.\n",
    "    For each user query, it retrieves the chat history, invokes the chain, stores the conversation,\n",
    "    and returns a list of enhanced user queries.\n",
    "\n",
    "    Args:\n",
    "        history_store: The object responsible for storing and retrieving conversation history.\n",
    "        conversation_list: List of user queries (strings) to process.\n",
    "        chain: The chain object with an 'invoke' method.\n",
    "        conv_id: The conversation id to store the conversation.\n",
    "\n",
    "    Returns:\n",
    "        List of enhanced user queries (one for each user query in conversation_list).\n",
    "    \"\"\"\n",
    "    enhanced_queries = []\n",
    "    for user_query in conversation_list:\n",
    "        # Retrieve chat history for the conversation\n",
    "        chat_history = history_store.get_conversation_as_lc_messages(str(conv_id))\n",
    "        # Invoke the chain to get the result\n",
    "        result = chain.invoke({\"user_query\": user_query, \"chat_history\": chat_history})\n",
    "        # Store the conversation\n",
    "        messages = [\n",
    "            {\"sender\": \"human\", \"content\": user_query},\n",
    "            {\"sender\": \"ai\", \"content\": result.enhanced_user_query},\n",
    "        ]\n",
    "        history_store.store_conversation(str(conv_id), messages)\n",
    "        # Collect the enhanced user query\n",
    "        enhanced_queries.append(result.enhanced_user_query)\n",
    "    return enhanced_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "124f77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-05 21:02:47.854\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mcheck_and_reset_index\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mreset_index is set to True. Deleting existing index at 'd:\\Study\\Programs\\TSAI\\EAG_V1\\Assignment_7_RAG_1\\2_URL_RAG\\history_index'\u001b[0m\n",
      "\u001b[32m2025-07-05 21:02:47.856\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mcheck_and_reset_index\u001b[0m:\u001b[36m32\u001b[0m - \u001b[32m\u001b[1mSuccessfully deleted index folder 'd:\\Study\\Programs\\TSAI\\EAG_V1\\Assignment_7_RAG_1\\2_URL_RAG\\history_index'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the capital city of France?', 'Tell me more about the history of France, particularly focusing on its capital, Paris.', 'List two famous landmarks in Paris, the capital city of France.']\n"
     ]
    }
   ],
   "source": [
    "conv_id = uuid.uuid4()\n",
    "memory_store = ConversationMemory(\n",
    "    embedder, index_folder=history_index_name, reset_index=True\n",
    ")\n",
    "conversation_list = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Tell me more about its history.\",\n",
    "    \"List two famous landmarks in that city.\",\n",
    "]\n",
    "enhanced_queries = process_conversation_and_enhance_query(\n",
    "    memory_store, conversation_list, perception_chain, conv_id\n",
    ")\n",
    "print(enhanced_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225837c",
   "metadata": {},
   "source": [
    "### Decision and action code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48ce43",
   "metadata": {},
   "source": [
    "- For the constraints of mcp we cannot use the decision node in jupter notebook , so we have executed the decision node in the test_client.py file and have saved the output in the test_client_output.pkl file\n",
    "- We will try to debug the action node here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b884bff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'client/test_client_output.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m decison_op = \u001b[33m\"\u001b[39m\u001b[33mclient/test_client_output.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecison_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m     data = json.load(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Study\\Programs\\TSAI\\EAG_V1\\venv_313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'client/test_client_output.json'"
     ]
    }
   ],
   "source": [
    "decison_op = \"client/test_client_output.json\"\n",
    "import json\n",
    "with open(decison_op, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169480db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
